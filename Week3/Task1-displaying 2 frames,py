import cv2
import mediapipe as mp
import numpy as np

# Initialize MediaPipe Hands
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=2,static_image_mode=False)
mp_draw = mp.solutions.drawing_utils

# Initialize webcam
cap1 = cv2.VideoCapture(0) #webcam
cap2=cv2.VideoCapture(1) #phone

while cap1.isOpened() and cap2.isOpened():
    # Read frame
    success1, frame1 = cap1.read()
    success2,frame2=cap2.read()

    if not success1 or not success2:
        print('Failed to get input from both cameras')
        break

    # Convert BGR to RGB
    rgbimage1=cv2.cvtColor(frame1,cv2.COLOR_BGR2RGB)
    rgbimage2=cv2.cvtColor(frame2,cv2.COLOR_BGR2RGB)

    # Process the frame for hand detection
    res1=hands.process(rgbimage1)
    res2=hands.process(rgbimage2)

    # Draw landmarks on both frames
    if res1.multi_hand_landmarks:
        for point in res1.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame1,point,mp_hands.HAND_CONNECTIONS)
    if res2.multi_hand_landmarks:
        for point in res2.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame2,point,mp_hands.HAND_CONNECTIONS)

    # Display the frame
    cv2.imshow('Video from webcam',frame1)
    cv2.imshow('Video from phone',frame2)

    # Exit when 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cap1.release()
cap2.release()
cv2.destroyAllWindows()

